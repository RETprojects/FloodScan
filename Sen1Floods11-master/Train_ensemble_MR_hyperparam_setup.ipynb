{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mApGSuvVrchZ"
      },
      "outputs": [],
      "source": [
        "! git clone https://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@github.com/RETprojects/FloodScan.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gA7UK8RerhfN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/FloodScan')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "snql5nNrtpyZ",
        "outputId": "13652254-ea74-4763-dbd8-5020d98dc3b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FloodScan\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/FloodScan/\n",
        "# !git checkout segmentation-visualization\n",
        "!git checkout main\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WfwqZWJ20t8W"
      },
      "outputs": [],
      "source": [
        "!cd /content/FloodScan/Sen1Floods11-master/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbu_ucRSo5zT"
      },
      "source": [
        "The following is an example of how to utilize our Sen1Floods11 dataset for training a FCNN. In this example, we train and validate on hand-labeled chips of flood events. However, our dataset includes several other options that are detailed in the README. To replace the dataset, as outlined further below, simply replace the train, test, and validation split csv's, and download the corresponding dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TQtMrI_VhKk"
      },
      "source": [
        "Authenticate Google Cloud Platform. Note that to run this code, you must connect your notebook runtime to a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qCEt8eNtU9Zm"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "!curl https://sdk.cloud.google.com | bash\n",
        "\n",
        "!gcloud init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YkUEnwXQVy4k"
      },
      "outputs": [],
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXGTA6vHVyJX"
      },
      "source": [
        "Install RasterIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NLlVutLzV_pZ"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLqL9C2Rg6eB"
      },
      "source": [
        "Define a model checkpoint folder, for storing network checkpoints during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yLlIhE-Hg-Ym",
        "outputId": "aec16a16-d0b9-432a-ede8-3c9757ce0e53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home\n"
          ]
        }
      ],
      "source": [
        "%cd /home\n",
        "!sudo mkdir checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwrDM4AjVnbU"
      },
      "source": [
        "Download train, test, and validation splits for both flood water. To download different train, test, and validation splits, simply replace these paths with the path to a csv containing the desired splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFLsGwdRWuO4"
      },
      "outputs": [],
      "source": [
        "!gsutil cp gs://sen1floods11/v1.1/splits/flood_handlabeled/flood_train_data.csv .\n",
        "!gsutil cp gs://sen1floods11/v1.1/splits/flood_handlabeled/flood_test_data.csv .\n",
        "!gsutil cp gs://sen1floods11/v1.1/splits/flood_handlabeled/flood_valid_data.csv ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCAXpuKVW3eV"
      },
      "source": [
        "Download raw train, test, and validation data. In this example, we are downloading train, test, and validation data of flood images which are hand labeled. However, you can simply replace these paths with whichever dataset you would like to use - further documentation of the Sen1Floods11 dataset and organization is available in the README."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ahAWnrSFW53S"
      },
      "outputs": [],
      "source": [
        "!sudo mkdir files\n",
        "!sudo mkdir files/Labels\n",
        "\n",
        "!sudo mkdir files/S2\n",
        "!gsutil -m -q rsync -r gs://sen1floods11/v1.1/data/flood_events/HandLabeled/S2Hand files/S2\n",
        "!sudo mkdir files/S1\n",
        "!gsutil -m -q rsync -r gs://sen1floods11/v1.1/data/flood_events/HandLabeled/S1Hand files/S1\n",
        "\n",
        "!gsutil -m -q rsync -r gs://sen1floods11/v1.1/data/flood_events/HandLabeled/LabelHand files/Labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flag for whether or not to generate augmented features\n",
        "augment_features_flag = True\n",
        "\n",
        "# Additional flag for type of features to keep\n",
        "# Options: \"All\", \"HSV\", \"S1\", \"S1+AWEI+NDWI+HSV\", \"S1+AWEI+NDWI\", \"S1+HSV\", \"AWEI+NDWI+HSV\"\n",
        "feature_set = \"AWEI+NDWI+HSV\"\n",
        "# feature_set = \"S1\""
      ],
      "metadata": {
        "id": "dA1u5jpXQhAz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_46CazV3XSCD"
      },
      "source": [
        "Define model training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fNYQywdWXeLM"
      },
      "outputs": [],
      "source": [
        "LR = 5e-4\n",
        "EPOCHS = 100\n",
        "EPOCHS_PER_UPDATE = 1\n",
        "RUNNAME = \"Sen1Floods11\"\n",
        "\n",
        "#set seed in line below\n",
        "seed_all = 12345\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "torch.manual_seed(seed_all)\n",
        "np.random.seed(seed_all)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.cuda.manual_seed_all(seed_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9FJmTnZXjxj"
      },
      "source": [
        "Define functions to process and augment training and testing images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mBkfav0Eajqg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# import torch\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as F\n",
        "import random\n",
        "from PIL import Image\n",
        "import csv\n",
        "import rasterio\n",
        "import os\n",
        "# import numpy as np\n",
        "\n",
        "class InMemoryDataset(torch.utils.data.Dataset):\n",
        "  \"\"\"\n",
        "  operation of this class has been modified to:\n",
        "    accomodate a dynamic number of channels\n",
        "    allow for calculation of channel mean and stdev values across training data, for normalization\n",
        "  \"\"\"\n",
        "\n",
        "  # def __init__(self, data_list, preprocess_func):\n",
        "  def __init__(self, data_list, norm_means, norm_stdvs, preprocess_func):\n",
        "    self.data_list = data_list\n",
        "    self.preprocess_func = preprocess_func\n",
        "    self.norm_means = norm_means\n",
        "    self.norm_stdvs = norm_stdvs\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    # return self.preprocess_func(self.data_list[i])\n",
        "    return self.preprocess_func(self.data_list[i], self.norm_means, self.norm_stdvs)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_list)\n",
        "\n",
        "\n",
        "# def processAndAugment(data):\n",
        "def processAndAugment(data, norm_means, norm_stdvs):\n",
        "  \"\"\"\n",
        "  this function has been modified to accomodate a dynamic number of input image channels\n",
        "  \"\"\"\n",
        "  (x,y) = data\n",
        "  im,label = x.copy(), y.copy()\n",
        "\n",
        "  # convert to PIL for easier transforms\n",
        "  # im1 = Image.fromarray(im[0])\n",
        "  # im2 = Image.fromarray(im[1])\n",
        "  im_list = []\n",
        "  for i in range(im.shape[0]):\n",
        "    im_list.append(Image.fromarray(im[i]))\n",
        "\n",
        "  label = Image.fromarray(label.squeeze())\n",
        "\n",
        "  # Get params for random transforms\n",
        "  # i, j, h, w = transforms.RandomCrop.get_params(im1, (256, 256))\n",
        "  i, j, h, w = transforms.RandomCrop.get_params(im_list[0], (256, 256))\n",
        "\n",
        "  # im1 = F.crop(im1, i, j, h, w)\n",
        "  # im2 = F.crop(im2, i, j, h, w)\n",
        "  for i in range(im.shape[0]):\n",
        "    im_list[i] = F.crop(im_list[i], i, j, h, w)\n",
        "\n",
        "  label = F.crop(label, i, j, h, w)\n",
        "\n",
        "  if random.random() > 0.5:\n",
        "    # im1 = F.hflip(im1)\n",
        "    # im2 = F.hflip(im2)\n",
        "    for i in range(im.shape[0]):\n",
        "        im_list[i] = F.hflip(im_list[i])\n",
        "    label = F.hflip(label)\n",
        "\n",
        "  if random.random() > 0.5:\n",
        "    # im1 = F.vflip(im1)\n",
        "    # im2 = F.vflip(im2)\n",
        "    for i in range(im.shape[0]):\n",
        "        im_list[i] = F.vflip(im_list[i])\n",
        "    label = F.vflip(label)\n",
        "\n",
        "  # norm = transforms.Normalize([0.6851, 0.5235], [0.0820, 0.1102])\n",
        "  norm = transforms.Normalize(norm_means, norm_stdvs)\n",
        "\n",
        "  # im = torch.stack([transforms.ToTensor()(im1).squeeze(), transforms.ToTensor()(im2).squeeze()])\n",
        "  im_list = [transforms.ToTensor()(i).squeeze() for i in im_list]\n",
        "  im = torch.stack(im_list)\n",
        "\n",
        "  im = norm(im)\n",
        "  label = transforms.ToTensor()(label).squeeze()\n",
        "  if torch.sum(label.gt(.003) * label.lt(.004)):\n",
        "    label *= 255\n",
        "  label = label.round()\n",
        "\n",
        "  return im, label\n",
        "\n",
        "\n",
        "# def processTestIm(data):\n",
        "def processTestIm(data, norm_means, norm_stdvs):\n",
        "  \"\"\"\n",
        "  this function has been modified to accomodate a dynamic number of input image channels\n",
        "  \"\"\"\n",
        "  (x,y) = data\n",
        "  im,label = x.copy(), y.copy()\n",
        "\n",
        "  # norm = transforms.Normalize([0.6851, 0.5235], [0.0820, 0.1102])\n",
        "  norm = transforms.Normalize(norm_means, norm_stdvs)\n",
        "\n",
        "  # convert to PIL for easier transforms\n",
        "  # im_c1 = Image.fromarray(im[0]).resize((512,512))\n",
        "  # im_c2 = Image.fromarray(im[1]).resize((512,512))\n",
        "  im_c_list = []\n",
        "  for i in range(im.shape[0]):\n",
        "          im_c = Image.fromarray(im[0]).resize((512,512))\n",
        "          im_c_list.append(im_c)\n",
        "  label = Image.fromarray(label.squeeze()).resize((512,512))\n",
        "\n",
        "  # im_c1s = [F.crop(im_c1, 0, 0, 256, 256), F.crop(im_c1, 0, 256, 256, 256),\n",
        "  #         F.crop(im_c1, 256, 0, 256, 256), F.crop(im_c1, 256, 256, 256, 256)]\n",
        "  # im_c2s = [F.crop(im_c2, 0, 0, 256, 256), F.crop(im_c2, 0, 256, 256, 256),\n",
        "  #         F.crop(im_c2, 256, 0, 256, 256), F.crop(im_c2, 256, 256, 256, 256)]\n",
        "  im_cs_list = []\n",
        "  for i in range(im.shape[0]):\n",
        "          im_cs_list.append([F.crop(im_c_list[i], 0, 0, 256, 256), F.crop(im_c_list[i], 0, 256, 256, 256),\n",
        "                          F.crop(im_c_list[i], 256, 0, 256, 256), F.crop(im_c_list[i], 256, 256, 256, 256)])\n",
        "  labels = [F.crop(label, 0, 0, 256, 256), F.crop(label, 0, 256, 256, 256),\n",
        "          F.crop(label, 256, 0, 256, 256), F.crop(label, 256, 256, 256, 256)]\n",
        "\n",
        "  # ims = [torch.stack((transforms.ToTensor()(x).squeeze(),\n",
        "  #                 transforms.ToTensor()(y).squeeze()))\n",
        "  #                 for (x,y) in zip(im_c1s, im_c2s)]\n",
        "  ims_list = []\n",
        "  for i in zip(*im_cs_list):\n",
        "          tensor_list = [transforms.ToTensor()(x).squeeze() for x in i]\n",
        "          ims_list.append(torch.stack(tensor_list))\n",
        "\n",
        "  # ims = [norm(im) for im in ims]\n",
        "  ims = [norm(im) for im in ims_list]\n",
        "  ims = torch.stack(ims)\n",
        "\n",
        "  labels = [(transforms.ToTensor()(label).squeeze()) for label in labels]\n",
        "  labels = torch.stack(labels)\n",
        "\n",
        "  if torch.sum(labels.gt(.003) * labels.lt(.004)):\n",
        "      labels *= 255\n",
        "  labels = labels.round()\n",
        "\n",
        "  return ims, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uBWEdLky34mt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# from https://github.com/NASA-IMPACT/hls-foundation-os/blob/main/exploration.ipynb\n",
        "# import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "import rasterio\n",
        "import yaml\n",
        "\n",
        "def load_raster(path, crop=None):\n",
        "    with rasterio.open(path) as src:\n",
        "        img = src.read()\n",
        "\n",
        "        # load first 6 bands\n",
        "        img = img[:6]\n",
        "\n",
        "        img = np.where(img == NO_DATA, NO_DATA_FLOAT, img)\n",
        "        if crop:\n",
        "            img = img[:, -crop[0]:, -crop[1]:]\n",
        "    return img\n",
        "\n",
        "def enhance_raster_for_visualization(raster, ref_img=None):\n",
        "    if ref_img is None:\n",
        "        ref_img = raster\n",
        "    channels = []\n",
        "    for channel in range(raster.shape[0]):\n",
        "        valid_mask = np.ones_like(ref_img[channel], dtype=bool)\n",
        "        valid_mask[ref_img[channel] == NO_DATA_FLOAT] = False\n",
        "        mins, maxs = np.percentile(ref_img[channel][valid_mask], PERCENTILES)\n",
        "        normalized_raster = (raster[channel] - mins) / (maxs - mins)\n",
        "        normalized_raster[~valid_mask] = 0\n",
        "        clipped = np.clip(normalized_raster, 0, 1)\n",
        "        channels.append(clipped)\n",
        "    clipped = np.stack(channels)\n",
        "    channels_last = np.moveaxis(clipped, 0, -1)[..., :3]\n",
        "    rgb = channels_last[..., ::-1]\n",
        "    return rgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzmZIRuoeAuJ"
      },
      "source": [
        "Load *flood water* train, test, and validation data from splits. In this example, this is the data we will use to train our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rQUnYCIBeG21",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "from time import time\n",
        "# import csv\n",
        "# import os\n",
        "# import numpy as np\n",
        "# import rasterio\n",
        "import cv2\n",
        "\n",
        "def getArrFlood(fname):\n",
        "  return rasterio.open(fname).read()\n",
        "\n",
        "def download_flood_water_data_from_list(l):\n",
        "  i = 0\n",
        "  tot_nan = 0\n",
        "  tot_good = 0\n",
        "  flood_data = []\n",
        "  for (im_fname_s1, im_fname_s2, mask_fname) in l:\n",
        "    if not os.path.exists(os.path.join(\"files/\", im_fname_s1)) or not os.path.exists(os.path.join(\"files/\", im_fname_s2)):\n",
        "      continue\n",
        "    arr_x_s1 = np.nan_to_num(getArrFlood(os.path.join(\"files/\", im_fname_s1)))\n",
        "    arr_x_s2 = np.nan_to_num(getArrFlood(os.path.join(\"files/\", im_fname_s2)))\n",
        "    arr_x = np.concatenate((arr_x_s2, arr_x_s1), axis=0)\n",
        "    arr_y = getArrFlood(os.path.join(\"files/\", mask_fname))\n",
        "    arr_y[arr_y == -1] = 255\n",
        "\n",
        "    # arr_x = np.clip(arr_x, -50, 1)\n",
        "    # arr_x = (arr_x + 50) / 51\n",
        "\n",
        "    if i % 100 == 0:\n",
        "      print(im_fname_s1, im_fname_s2, mask_fname)\n",
        "    i += 1\n",
        "\n",
        "    # Separate logic for augmented features\n",
        "    if augment_features_flag:\n",
        "      # Normalised difference water index\n",
        "      arr_x_NDWI  = np.expand_dims((arr_x[2]-arr_x[7])/(arr_x[2]+arr_x[7]+1e-10), axis=0)\n",
        "      arr_x_MNDWI = np.expand_dims((arr_x[2]-arr_x[11])/(arr_x[2]+arr_x[11]+1e-10), axis=0)\n",
        "\n",
        "      # Calculate water extraction index\n",
        "      arr_x_AWEI  = np.expand_dims(4*(arr_x[2]-arr_x[11])-0.25*(arr_x[7]+11*arr_x[12]), axis=0)\n",
        "      arr_x_AWEISH = np.expand_dims((arr_x[1]+2.5*arr_x[2] - 1.5*(arr_x[7]+arr_x[11]) - (arr_x[12])/4), axis=0)\n",
        "\n",
        "      # Calculate HSV - using S2 spectrums (O3)\n",
        "      arr_x_rgb = np.moveaxis(arr_x[np.array([12,7,3]),:,:], 0, -1).astype(np.uint8)\n",
        "      arr_x_HSV = cv2.cvtColor(arr_x_rgb, cv2.COLOR_RGB2HSV)\n",
        "      arr_x_HSV = np.moveaxis(arr_x_HSV, -1, 0)\n",
        "      arr_x_combined = np.concatenate((arr_x, arr_x_NDWI, arr_x_MNDWI, arr_x_AWEI, arr_x_AWEISH, arr_x_HSV), axis=0)\n",
        "\n",
        "    # Subset features\n",
        "    # Options: \"All\", \"HSV\", \"S1\", \"S1+AWEI+NDWI+HSV\", \"AWEI+NDWI+HSV\", \"S1+AWEI+NDWI\", \"S1+HSV\"\n",
        "    if feature_set == \"All\" :\n",
        "      flood_data.append((arr_x_combined,arr_y))\n",
        "    elif feature_set == \"HSV\":\n",
        "      flood_data.append((arr_x_HSV,arr_y))\n",
        "    elif feature_set == \"S1\":\n",
        "      flood_data.append((arr_x_s1,arr_y))\n",
        "    elif feature_set == \"S1+AWEI+NDWI+HSV\":\n",
        "      flood_data.append((np.concatenate((arr_x_s1, arr_x_NDWI, arr_x_MNDWI, arr_x_AWEI, arr_x_AWEISH, arr_x_HSV), axis=0),arr_y))\n",
        "    elif feature_set == \"AWEI+NDWI+HSV\":\n",
        "      flood_data.append((np.concatenate((arr_x_s1, arr_x_NDWI, arr_x_MNDWI, arr_x_HSV), axis=0),arr_y))\n",
        "    elif feature_set == \"S1+AWEI+NDWI\":\n",
        "      flood_data.append((np.concatenate((arr_x_s1, arr_x_NDWI, arr_x_MNDWI, arr_x_AWEI, arr_x_AWEISH), axis=0),arr_y))\n",
        "    elif feature_set == \"S1+HSV\":\n",
        "      flood_data.append((np.concatenate((arr_x_s1, arr_x_HSV), axis=0),arr_y))\n",
        "\n",
        "  return flood_data\n",
        "\n",
        "def load_flood_train_data(input_root_s1, input_root_s2, label_root):\n",
        "  fname = \"flood_train_data.csv\"\n",
        "  training_files = []\n",
        "  with open(fname) as f:\n",
        "    for line in csv.reader(f):\n",
        "      line_s2 = line[0].replace('_S1Hand', '_S2Hand')\n",
        "      training_files.append(tuple((input_root_s1+line[0], input_root_s2+line_s2, label_root+line[1])))\n",
        "\n",
        "  return download_flood_water_data_from_list(training_files)\n",
        "\n",
        "def load_flood_valid_data(input_root_s1, input_root_s2, label_root):\n",
        "  fname = \"flood_valid_data.csv\"\n",
        "  validation_files = []\n",
        "  with open(fname) as f:\n",
        "    for line in csv.reader(f):\n",
        "      line_s2 = line[0].replace('_S1Hand', '_S2Hand')\n",
        "      validation_files.append(tuple((input_root_s1+line[0], input_root_s2+line_s2, label_root+line[1])))\n",
        "\n",
        "  return download_flood_water_data_from_list(validation_files)\n",
        "\n",
        "def load_flood_test_data(input_root_s1, input_root_s2, label_root):\n",
        "  fname = \"flood_test_data.csv\"\n",
        "  testing_files = []\n",
        "  with open(fname) as f:\n",
        "    for line in csv.reader(f):\n",
        "      line_s2 = line[0].replace('_S1Hand', '_S2Hand')\n",
        "      testing_files.append(tuple((input_root_s1+line[0], input_root_s2+line_s2, label_root+line[1])))\n",
        "\n",
        "  return download_flood_water_data_from_list(testing_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFp9jrHYfOUh"
      },
      "source": [
        "Load training data and validation data. Note that here, we have chosen to train and validate our model on flood data. However, you can simply replace the load function call with one of the options defined above to load a different dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcqPlsjBffXx"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "train_data = load_flood_train_data('S1/', 'S2/', 'Labels/')\n",
        "\n",
        "### mean and stdev calculations for normalization sections in InMemoryDataset class\n",
        "#### from Sen1Floods11 paper:\n",
        "# \"\"\"We then perform mean and standard deviation normalization\n",
        "# using the mean and standard deviation computed\n",
        "# over the hand labeled training dataset ([0.6851, 0.5235], [0.0820, 0.1102]).\"\"\"\n",
        "channels = train_data[0][0].shape[0]\n",
        "norm_means = []\n",
        "norm_stdvs = []\n",
        "for channel in range(channels):\n",
        "    x_list_means = []\n",
        "    x_list_stdvs = []\n",
        "    for x, y in train_data:\n",
        "        x_list_means.append(np.mean(x[channel,:,:]))\n",
        "        x_list_stdvs.append(np.std(x[channel,:,:]))\n",
        "    norm_means.append(float(np.mean(x_list_means)))\n",
        "    norm_stdvs.append(float(np.std(x_list_stdvs)))\n",
        "\n",
        "# train_dataset = InMemoryDataset(train_data, processAndAugment)\n",
        "train_dataset = InMemoryDataset(train_data, norm_means, norm_stdvs, processAndAugment)\n",
        "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, sampler=None,\n",
        "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, sampler=None,\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, sampler=None,\n",
        "                  batch_sampler=None, num_workers=0, collate_fn=None,\n",
        "                  pin_memory=True, drop_last=False, timeout=0,\n",
        "                  worker_init_fn=None)\n",
        "train_iter = iter(train_loader)\n",
        "\n",
        "valid_data = load_flood_valid_data('S1/', 'S2/', 'Labels/')\n",
        "\n",
        "# valid_dataset = InMemoryDataset(valid_data, processTestIm)\n",
        "valid_dataset = InMemoryDataset(valid_data, norm_means, norm_stdvs, processTestIm)\n",
        "# valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=4, shuffle=True, sampler=None,\n",
        "# valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=True, sampler=None,\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=8, shuffle=True, sampler=None,\n",
        "                  batch_sampler=None, num_workers=0, collate_fn=lambda x: (torch.cat([a[0] for a in x], 0), torch.cat([a[1] for a in x], 0)),\n",
        "                  pin_memory=True, drop_last=False, timeout=0,\n",
        "                  worker_init_fn=None)\n",
        "valid_iter = iter(valid_loader)\n",
        "\n",
        "test_data = load_flood_test_data('S1/', 'S2/', 'Labels/')\n",
        "\n",
        "test_dataset = InMemoryDataset(test_data, norm_means, norm_stdvs, processTestIm)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=True, sampler=None,\n",
        "                  batch_sampler=None, num_workers=0, collate_fn=lambda x: (torch.cat([a[0] for a in x], 0), torch.cat([a[1] for a in x], 0)),\n",
        "                  pin_memory=True, drop_last=False, timeout=0,\n",
        "                  worker_init_fn=None)\n",
        "test_iter = iter(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3aAhUi2fp7M"
      },
      "source": [
        "Define the network. For our purposes, we use ResNet50. However, if you wish to test a different model framework, optimizer, or loss function you can simply replace those here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mQ3SomTRbBv",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# import UNet\n",
        "%cd /../content/FloodScan/Sen1Floods11-master/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "# import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        features = init_features\n",
        "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(\n",
        "            features * 16, features * 8, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
        "        self.upconv3 = nn.ConvTranspose2d(\n",
        "            features * 8, features * 4, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
        "        self.upconv2 = nn.ConvTranspose2d(\n",
        "            features * 4, features * 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
        "        self.upconv1 = nn.ConvTranspose2d(\n",
        "            features * 2, features, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
        "        )\n",
        "\n",
        "        # self.apply(self._init_weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(self.pool1(enc1))\n",
        "        enc3 = self.encoder3(self.pool2(enc2))\n",
        "        enc4 = self.encoder4(self.pool3(enc3))\n",
        "\n",
        "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
        "\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
        "        dec4 = self.decoder4(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "        return torch.sigmoid(self.conv(dec1))\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        # if isinstance(module, UNet._block):\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            # Initialize weights using your custom logic\n",
        "            nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
        "            # if module.bias is not None:\n",
        "            #     nn.init.zeros_(module.bias)\n",
        "                  # nn.init.constant_(linear_layer.bias, 0.1)\n",
        "\n",
        "    @staticmethod\n",
        "    def _block(in_channels, features, name):\n",
        "        return nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\n",
        "                        name + \"conv1\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=in_channels,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            # bias=False,\n",
        "                            bias=True,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
        "                    (\n",
        "                        name + \"conv2\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=features,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            # bias=False,\n",
        "                            bias=True,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
        "                ]\n",
        "            )\n",
        "        )"
      ],
      "metadata": {
        "id": "CKiiPw-MHj84"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cp4uXI1f9dr",
        "outputId": "06c22046-386d-40ef-c258-cb4ebae69731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet input channels: 7\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# import torch\n",
        "import torchvision.models as models\n",
        "# import torch.nn as nn\n",
        "\n",
        "# net = models.segmentation.fcn_resnet50(pretrained=False, num_classes=2, pretrained_backbone=False)\n",
        "# net.backbone.conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "### Unet code\n",
        "# from unet import UNet\n",
        "# net = UNet(in_channels=9, out_channels=2)\n",
        "# net = UNet(in_channels=train_data[0][0].shape[0], out_channels=2, init_features=32)\n",
        "# net = UNet(in_channels=train_data[0][0].shape[0], out_channels=2, init_features=16)\n",
        "net = UNet(in_channels=train_data[0][0].shape[0], out_channels=2, init_features=64)\n",
        "net.cuda()\n",
        "###\n",
        "\n",
        "LR = 0.01\n",
        "weight_decay = 0.5\n",
        "weight = [1,100]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1,8]).float().cuda(), ignore_index=255, reduction='mean')\n",
        "optimizer = torch.optim.AdamW(net.parameters(),lr=LR, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, len(train_loader) * 10, T_mult=2, eta_min=0, last_epoch=-1)\n",
        "\n",
        "num_groups_param = 16\n",
        "# def convertBNtoGN(module, num_groups=16):\n",
        "def convertBNtoGN(module, num_groups=num_groups_param):\n",
        "  if isinstance(module, torch.nn.modules.batchnorm.BatchNorm2d):\n",
        "    return nn.GroupNorm(num_groups, module.num_features,\n",
        "                        eps=module.eps, affine=module.affine)\n",
        "    if module.affine:\n",
        "        mod.weight.data = module.weight.data.clone().detach()\n",
        "        mod.bias.data = module.bias.data.clone().detach()\n",
        "\n",
        "  for name, child in module.named_children():\n",
        "      module.add_module(name, convertBNtoGN(child, num_groups=num_groups))\n",
        "\n",
        "  return module\n",
        "\n",
        "# net = convertBNtoGN(net)\n",
        "\n",
        "print(\"UNet input channels: {}\".format(train_data[0][0].shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Sy3ALGgQjf"
      },
      "source": [
        "Define assessment metrics. For our purposes, we use overall accuracy and mean intersection over union. However, we also include functions for calculating true positives, false positives, true negatives, and false negatives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bwxC-fVBgUIb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "def computeIOU(output, target):\n",
        "  output = torch.argmax(output, dim=1).flatten()\n",
        "  target = target.flatten()\n",
        "\n",
        "  no_ignore = target.ne(255).cuda()\n",
        "  output = output.masked_select(no_ignore)\n",
        "  target = target.masked_select(no_ignore)\n",
        "  intersection = torch.sum(output * target)\n",
        "  union = torch.sum(target) + torch.sum(output) - intersection\n",
        "  iou = (intersection + .0000001) / (union + .0000001)\n",
        "\n",
        "  if iou != iou:\n",
        "    print(\"failed, replacing with 0\")\n",
        "    iou = torch.tensor(0).float()\n",
        "\n",
        "  return iou\n",
        "\n",
        "def computeAccuracy(output, target):\n",
        "  output = torch.argmax(output, dim=1).flatten()\n",
        "  target = target.flatten()\n",
        "\n",
        "  no_ignore = target.ne(255).cuda()\n",
        "  output = output.masked_select(no_ignore)\n",
        "  target = target.masked_select(no_ignore)\n",
        "  correct = torch.sum(output.eq(target))\n",
        "\n",
        "  return correct.float() / len(target)\n",
        "\n",
        "def truePositives(output, target):\n",
        "  output = torch.argmax(output, dim=1).flatten()\n",
        "  target = target.flatten()\n",
        "  no_ignore = target.ne(255).cuda()\n",
        "  output = output.masked_select(no_ignore)\n",
        "  target = target.masked_select(no_ignore)\n",
        "  correct = torch.sum(output * target)\n",
        "\n",
        "  return correct\n",
        "\n",
        "def trueNegatives(output, target):\n",
        "  output = torch.argmax(output, dim=1).flatten()\n",
        "  target = target.flatten()\n",
        "  no_ignore = target.ne(255).cuda()\n",
        "  output = output.masked_select(no_ignore)\n",
        "  target = target.masked_select(no_ignore)\n",
        "  output = (output == 0)\n",
        "  target = (target == 0)\n",
        "  correct = torch.sum(output * target)\n",
        "\n",
        "  return correct\n",
        "\n",
        "def falsePositives(output, target):\n",
        "  output = torch.argmax(output, dim=1).flatten()\n",
        "  target = target.flatten()\n",
        "  no_ignore = target.ne(255).cuda()\n",
        "  output = output.masked_select(no_ignore)\n",
        "  target = target.masked_select(no_ignore)\n",
        "  output = (output == 1)\n",
        "  target = (target == 0)\n",
        "  correct = torch.sum(output * target)\n",
        "\n",
        "  return correct\n",
        "\n",
        "def falseNegatives(output, target):\n",
        "  output = torch.argmax(output, dim=1).flatten()\n",
        "  target = target.flatten()\n",
        "  no_ignore = target.ne(255).cuda()\n",
        "  output = output.masked_select(no_ignore)\n",
        "  target = target.masked_select(no_ignore)\n",
        "  output = (output == 0)\n",
        "  target = (target == 1)\n",
        "  correct = torch.sum(output * target)\n",
        "\n",
        "  return correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lun5tGoYgjWX"
      },
      "source": [
        "Define training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DubsYZ8GgkxD",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "training_losses = []\n",
        "training_accuracies = []\n",
        "training_ious = []\n",
        "\n",
        "\n",
        "training_precisions = []\n",
        "training_recalls = []\n",
        "training_f1s = []\n",
        "\n",
        "def train_loop(inputs, labels, net, optimizer, scheduler):\n",
        "  global running_loss\n",
        "  global running_iou\n",
        "  global running_count\n",
        "  global running_accuracy\n",
        "\n",
        "\n",
        "  global running_precision\n",
        "  global running_recall\n",
        "  global running_f1\n",
        "\n",
        "  # zero the parameter gradients\n",
        "  optimizer.zero_grad()\n",
        "  net = net.cuda()\n",
        "\n",
        "  # forward + backward + optimize\n",
        "  outputs = net(inputs.cuda())\n",
        "\n",
        "  # loss = criterion(outputs[\"out\"], labels.long().cuda())\n",
        "  ### Unet code\n",
        "  loss = criterion(outputs, labels.long().cuda())\n",
        "  ###\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  scheduler.step()\n",
        "\n",
        "  running_loss += loss\n",
        "\n",
        "  # running_iou += computeIOU(outputs[\"out\"], labels.cuda())\n",
        "  ### Unet code\n",
        "  running_iou += computeIOU(outputs, labels.cuda())\n",
        "  ###\n",
        "\n",
        "  # running_accuracy += computeAccuracy(outputs[\"out\"], labels.cuda())\n",
        "  ### Unet code\n",
        "  running_accuracy += computeAccuracy(outputs, labels.cuda())\n",
        "  ###\n",
        "\n",
        "  running_count += 1\n",
        "\n",
        "\n",
        "  tp = truePositives(outputs, labels.cuda())\n",
        "  fp = falsePositives(outputs, labels.cuda())\n",
        "  fn = falseNegatives(outputs, labels.cuda())\n",
        "\n",
        "  precision_ = tp/(tp + fp)\n",
        "  recall_ = tp/(tp + fn)\n",
        "\n",
        "  running_precision += precision_\n",
        "  running_recall += recall_\n",
        "  running_f1 += (2 * precision_ * recall_)/(precision_ + recall_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM3Jz__hgshh"
      },
      "source": [
        "Define validation loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_GmVaoRvguic"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "valid_losses = []\n",
        "valid_accuracies = []\n",
        "valid_ious = []\n",
        "\n",
        "valid_precisions = []\n",
        "valid_recalls = []\n",
        "valid_f1s = []\n",
        "\n",
        "def validation_loop(validation_data_loader, test_data_loader, net):\n",
        "  global running_loss\n",
        "  global running_iou\n",
        "  global running_count\n",
        "  global running_accuracy\n",
        "  global max_valid_iou\n",
        "\n",
        "  global training_losses\n",
        "  global training_accuracies\n",
        "  global training_ious\n",
        "  global valid_losses\n",
        "  global valid_accuracies\n",
        "  global valid_ious\n",
        "  global test_losses\n",
        "  global test_accuracies\n",
        "  global test_ious\n",
        "\n",
        "\n",
        "  global running_precision\n",
        "  global running_recall\n",
        "  global running_f1\n",
        "\n",
        "  global training_precisions\n",
        "  global training_recalls\n",
        "  global training_f1s\n",
        "  global valid_precisions\n",
        "  global valid_recalls\n",
        "  global valid_f1s\n",
        "  global test_precisions\n",
        "  global test_recalls\n",
        "  global test_f1s\n",
        "\n",
        "  global max_valid_iou_state_dict\n",
        "\n",
        "\n",
        "  net = net.eval()\n",
        "  net = net.cuda()\n",
        "  count = 0\n",
        "  iou = 0\n",
        "  loss = 0\n",
        "  accuracy = 0\n",
        "\n",
        "  precision = 0\n",
        "  recall = 0\n",
        "  f1 = 0\n",
        "\n",
        "  count_test = 0\n",
        "  iou_test = 0\n",
        "  loss_test = 0\n",
        "  accuracy_test = 0\n",
        "\n",
        "  precision_test = 0\n",
        "  recall_test = 0\n",
        "  f1_test = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "      for (images, labels) in test_data_loader:\n",
        "          net = net.cuda()\n",
        "          outputs = net(images.cuda())\n",
        "\n",
        "          ### Unet code\n",
        "          test_loss = criterion(outputs, labels.long().cuda())\n",
        "          test_iou = computeIOU(outputs, labels.cuda())\n",
        "          test_accuracy = computeAccuracy(outputs, labels.cuda())\n",
        "          ###\n",
        "\n",
        "          iou_test += test_iou\n",
        "          loss_test += test_loss\n",
        "          accuracy_test += test_accuracy\n",
        "          count_test += 1\n",
        "\n",
        "          tp = truePositives(outputs, labels.cuda())\n",
        "          fp = falsePositives(outputs, labels.cuda())\n",
        "          fn = falseNegatives(outputs, labels.cuda())\n",
        "\n",
        "          test_precision = tp/(tp + fp)\n",
        "          test_recall = tp/(tp + fn)\n",
        "          test_f1 = (2 * test_precision * test_recall)/(test_precision + test_recall)\n",
        "\n",
        "          precision_test += test_precision\n",
        "          recall_test += test_recall\n",
        "          f1_test += test_f1\n",
        "\n",
        "      i = 0\n",
        "      for (images, labels) in validation_data_loader:\n",
        "          net = net.cuda()\n",
        "          outputs = net(images.cuda())\n",
        "\n",
        "          # # print a specific segmentation\n",
        "          # if i == 0:\n",
        "          #   # w/ help from: https://github.com/NASA-IMPACT/hls-foundation-os/blob/main/exploration.ipynb\n",
        "          #   # print the new segmentation on a specific satellite image\n",
        "          #   fig, ax = plt.subplots(1, 3, figsize=(15, 10))\n",
        "          #   norm = matplotlib.colors.Normalize(vmin=0, vmax=2)\n",
        "          #   # get the segmentation\n",
        "          #   ax[0].imshow(images[0][0].squeeze())\n",
        "          #   ax[1].imshow(outputs[0][0].cpu(), norm=norm, cmap=\"jet\")\n",
        "          #   ax[2].imshow(images[0][0].squeeze())\n",
        "          #   ax[2].imshow(outputs[0][0].cpu(), cmap=\"jet\", alpha=0.3, norm=norm)\n",
        "          #   for subplot in ax:\n",
        "          #     subplot.axis('off')\n",
        "          # i += 1\n",
        "\n",
        "          # valid_loss = criterion(outputs[\"out\"], labels.long().cuda())\n",
        "          # valid_iou = computeIOU(outputs[\"out\"], labels.cuda())\n",
        "          # valid_accuracy = computeAccuracy(outputs[\"out\"], labels.cuda())\n",
        "          ### Unet code\n",
        "          valid_loss = criterion(outputs, labels.long().cuda())\n",
        "          valid_iou = computeIOU(outputs, labels.cuda())\n",
        "          valid_accuracy = computeAccuracy(outputs, labels.cuda())\n",
        "          ###\n",
        "\n",
        "          iou += valid_iou\n",
        "          loss += valid_loss\n",
        "          accuracy += valid_accuracy\n",
        "          count += 1\n",
        "\n",
        "\n",
        "          tp = truePositives(outputs, labels.cuda())\n",
        "          fp = falsePositives(outputs, labels.cuda())\n",
        "          fn = falseNegatives(outputs, labels.cuda())\n",
        "\n",
        "          valid_precision = tp/(tp + fp)\n",
        "          valid_recall = tp/(tp + fn)\n",
        "          valid_f1 = (2 * valid_precision * valid_recall)/(valid_precision + valid_recall)\n",
        "\n",
        "          precision += valid_precision\n",
        "          recall += valid_recall\n",
        "          f1 += valid_f1\n",
        "\n",
        "  iou = iou / count\n",
        "  accuracy = accuracy / count\n",
        "\n",
        "\n",
        "  if iou > max_valid_iou:\n",
        "    max_valid_iou = iou\n",
        "    save_path = os.path.join(\"checkpoints\", \"{}_{}_{}.cp\".format(RUNNAME, i, iou.item()))\n",
        "    torch.save(net.state_dict(), save_path)\n",
        "    print(\"model saved at\", save_path)\n",
        "    max_valid_iou_state_dict = net.state_dict()\n",
        "\n",
        "  loss = loss / count\n",
        "\n",
        "  precision = precision / count\n",
        "  recall = recall / count\n",
        "  f1 = f1 / count\n",
        "\n",
        "  # Test metrics\n",
        "  iou_test = iou_test / count\n",
        "  accuracy_test = accuracy_test / count\n",
        "  loss_test = loss_test / count\n",
        "  precision_test = precision_test / count\n",
        "  recall_test = recall_test / count\n",
        "  f1_test = f1_test / count\n",
        "\n",
        "  print(\"Training Loss:\", running_loss / running_count)\n",
        "  print(\"Training IOU:\", running_iou / running_count)\n",
        "  print(\"Training Accuracy:\", running_accuracy / running_count)\n",
        "\n",
        "  print(\"Training Precision:\", running_precision / running_count)\n",
        "  print(\"Training Recall:\", running_recall / running_count)\n",
        "  print(\"Training F1:\", running_f1 / running_count)\n",
        "\n",
        "  print(\"\")\n",
        "\n",
        "  print(\"Validation Loss:\", loss)\n",
        "  print(\"Validation IOU:\", iou)\n",
        "  print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "  print(\"Validation Precision:\", precision)\n",
        "  print(\"Validation Recall:\", recall)\n",
        "  print(\"Validation F1:\", f1)\n",
        "\n",
        "  print(\"\")\n",
        "\n",
        "  print(\"Test Loss:\", loss_test)\n",
        "  print(\"Test IOU:\", iou_test)\n",
        "  print(\"Test Accuracy:\", accuracy_test)\n",
        "\n",
        "  print(\"Test Precision:\", precision_test)\n",
        "  print(\"Test Recall:\", recall_test)\n",
        "  print(\"Test F1:\", f1_test)\n",
        "\n",
        "  training_losses.append(running_loss / running_count)\n",
        "  training_accuracies.append(running_accuracy / running_count)\n",
        "  training_ious.append(running_iou / running_count)\n",
        "  valid_losses.append(loss)\n",
        "  valid_accuracies.append(accuracy)\n",
        "  valid_ious.append(iou)\n",
        "\n",
        "  training_precisions.append(running_precision / running_count)\n",
        "  training_recalls.append(running_recall / running_count)\n",
        "  training_f1s.append(running_f1 / running_count)\n",
        "  valid_precisions.append(precision)\n",
        "  valid_recalls.append(recall)\n",
        "  valid_f1s.append(f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBMattYshiUj"
      },
      "source": [
        "Define testing loop (here, you can replace assessment metrics)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mI_mhL_ehjot",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "def test_loop(test_data_loader, net):\n",
        "  net = net.eval()\n",
        "  net = net.cuda()\n",
        "  count = 0\n",
        "  iou = 0\n",
        "  loss = 0\n",
        "  accuracy = 0\n",
        "\n",
        "  precision = 0\n",
        "  recall = 0\n",
        "  f1 = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for (images, labels) in tqdm(test_data_loader):\n",
        "          net = net.cuda()\n",
        "          outputs = net(images.cuda())\n",
        "\n",
        "          # valid_loss = criterion(outputs[\"out\"], labels.long().cuda())\n",
        "          # valid_iou = computeIOU(outputs[\"out\"], labels.cuda())\n",
        "          ### Unet code\n",
        "          valid_loss = criterion(outputs, labels.long().cuda())\n",
        "          valid_iou = computeIOU(outputs, labels.cuda())\n",
        "          ###\n",
        "\n",
        "          iou += valid_iou\n",
        "\n",
        "          # accuracy += computeAccuracy(outputs[\"out\"], labels.cuda())\n",
        "          ### Unet code\n",
        "          accuracy += computeAccuracy(outputs, labels.cuda())\n",
        "          ###\n",
        "\n",
        "          count += 1\n",
        "\n",
        "          tp = truePositives(outputs, labels.cuda())\n",
        "          fp = falsePositives(outputs, labels.cuda())\n",
        "          fn = falseNegatives(outputs, labels.cuda())\n",
        "\n",
        "          valid_precision = tp/(tp + fp)\n",
        "          valid_recall = tp/(tp + fn)\n",
        "          valid_f1 = (2 * valid_precision * valid_recall)/(valid_precision + valid_recall)\n",
        "\n",
        "          precision += valid_precision\n",
        "          recall += valid_recall\n",
        "          f1 += valid_f1\n",
        "\n",
        "  iou = iou / count\n",
        "  print(\"Test IOU:\", iou)\n",
        "  print(\"Test Accuracy:\", accuracy / count)\n",
        "\n",
        "  print(\"Test Precision:\", precision / count)\n",
        "  print(\"Test Recall:\", recall / count)\n",
        "  print(\"Test F1:\", f1 / count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy9Fii06h17Q"
      },
      "source": [
        "Define training and validation scheme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NZuKVC6wh4Go",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "# import matplotlib\n",
        "\n",
        "running_loss = 0\n",
        "running_iou = 0\n",
        "running_count = 0\n",
        "running_accuracy = 0\n",
        "\n",
        "training_losses = []\n",
        "training_accuracies = []\n",
        "training_ious = []\n",
        "valid_losses = []\n",
        "valid_accuracies = []\n",
        "valid_ious = []\n",
        "\n",
        "\n",
        "running_precision = 0\n",
        "running_recall = 0\n",
        "running_f1 = 0\n",
        "\n",
        "training_precisions = []\n",
        "training_recalls = []\n",
        "training_f1s = []\n",
        "valid_precisions = []\n",
        "valid_recalls = []\n",
        "valid_f1s = []\n",
        "\n",
        "\n",
        "def train_epoch(net, optimizer, scheduler, train_iter):\n",
        "  for (inputs, labels) in tqdm(train_iter):\n",
        "    train_loop(inputs.cuda(), labels.cuda(), net.cuda(), optimizer, scheduler)\n",
        "\n",
        "\n",
        "def train_validation_loop(net, optimizer, scheduler, train_loader,\n",
        "                          valid_loader, test_loader, num_epochs, cur_epoch):\n",
        "  global running_loss\n",
        "  global running_iou\n",
        "  global running_count\n",
        "  global running_accuracy\n",
        "\n",
        "\n",
        "  global running_precision\n",
        "  global running_recall\n",
        "  global running_f1\n",
        "\n",
        "\n",
        "  net = net.train()\n",
        "  running_loss = 0\n",
        "  running_iou = 0\n",
        "  running_count = 0\n",
        "  running_accuracy = 0\n",
        "\n",
        "  running_precision = 0\n",
        "  running_recall = 0\n",
        "  running_f1 = 0\n",
        "\n",
        "  for i in tqdm(range(num_epochs)):\n",
        "    train_iter = iter(train_loader)\n",
        "    train_epoch(net, optimizer, scheduler, train_iter)\n",
        "  clear_output()\n",
        "\n",
        "  print(\"Current Epoch:\", cur_epoch)\n",
        "  validation_loop(iter(valid_loader), iter(test_loader), net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3I88aY5iAWD"
      },
      "source": [
        "Train model and assess metrics over epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UtKxoF66CX6",
        "outputId": "a0c456de-ff1c-4a22-8d36-27e30ae00349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home\n"
          ]
        }
      ],
      "source": [
        "%cd /../home/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBHEu6cz_hpQ"
      },
      "source": [
        "#### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oTPAKEL_hpR",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "#param_grid = {\n",
        "#    'LR': [1e-3, 5e-4, 1e-4],\n",
        "#    'weight': [[1, 4], [1, 8], [1, 12]],\n",
        "#    'num_groups': [8, 16, 32],\n",
        "#    'dropout': [0.2, 0.5],  # Add dropout rates\n",
        "#    'weight_decay': [1e-4, 1e-5],  # Add weight decay values\n",
        "#    'momentum': [0.9, 0.99],  # Add momentum values\n",
        "#}\n",
        "\n",
        "param_grid = {\n",
        "    'LR': [1e-4, 1e-3, 1e-2],\n",
        "    'weight': [[1, 100], [1, 1000]],\n",
        "    # 'num_groups': [8, 16, 32],\n",
        "    'weight_decay': [1e-2, 5e-2, 1e-1],\n",
        "    'init_features': [32, 64]\n",
        "}\n",
        "\n",
        "EPOCHS_PER_UPDATE = 1\n",
        "\n",
        "# Create a list of all hyperparameter combinations\n",
        "param_combinations = list(ParameterGrid(param_grid))\n",
        "max_valid_iou = 0\n",
        "best_iou = 0\n",
        "best_accuracy = 0\n",
        "best_params_iou = {}  # Store best params for IOU\n",
        "best_params_accuracy = {}\n",
        "\n",
        "# Loop over all hyperparameter combinations\n",
        "for params in param_combinations:\n",
        "    print(str(param_combinations.index(params)) + \"/\" + str(len(param_combinations)))\n",
        "\n",
        "    #Set seeds for individual hyperparameter tuning run\n",
        "    torch.manual_seed(seed_all)\n",
        "    np.random.seed(seed_all)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.cuda.manual_seed_all(seed_all)\n",
        "\n",
        "    # Create a new model with the current hyperparameters\n",
        "    #tuning_net = models.segmentation.fcn_resnet50(pretrained=False, num_classes=2, pretrained_backbone=False)\n",
        "    # tuning_net = UNet(in_channels=2, out_channels=2)\n",
        "    tuning_net = UNet(in_channels=train_data[0][0].shape[0], out_channels=2,\n",
        "                      init_features=params['init_features'])\n",
        "    tuning_net.cuda()\n",
        "\n",
        "    tuning_criterion = nn.CrossEntropyLoss(weight=torch.tensor(params['weight']).float().cuda(), ignore_index=255)\n",
        "    tuning_optimizer = torch.optim.AdamW(tuning_net.parameters(), lr=params['LR'],\n",
        "                                  weight_decay=params['weight_decay'])\n",
        "    # tuning_optimizer = torch.optim.AdamW(tuning_net.parameters(), lr=params['LR'])\n",
        "    # tuning_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(tuning_optimizer, len(train_loader) * 10, T_mult=2, eta_min=0, last_epoch=-1)\n",
        "    tuning_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(tuning_optimizer, 5, T_mult=2, eta_min=0, last_epoch=-1)\n",
        "\n",
        "    # tuning_net = convertBNtoGN(tuning_net, num_groups=params['num_groups'])\n",
        "    #tuning_net.backbone.conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
        "\n",
        "    # Train and validate the model with early stopping\n",
        "    patience = 10  # Number of epochs to wait for improvement\n",
        "    epochs_without_improvement = 0\n",
        "    #for i in range(EPOCHS):\n",
        "    for i in range(12):\n",
        "        print(str(param_combinations.index(params)) + \"/\" + str(len(param_combinations)))\n",
        "\n",
        "        train_validation_loop(tuning_net, tuning_optimizer, tuning_scheduler, train_loader, valid_loader, test_loader, EPOCHS_PER_UPDATE, i)\n",
        "\n",
        "        # Check for improvement in IOU and accuracy\n",
        "        if valid_ious[-1] > best_iou:\n",
        "            best_iou = valid_ious[-1]\n",
        "            best_params_iou = params\n",
        "            epochs_without_improvement = 0\n",
        "\n",
        "        if valid_accuracies[-1] > best_accuracy:\n",
        "            best_accuracy = valid_accuracies[-1]\n",
        "            best_params_accuracy = params\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= patience:\n",
        "                print(f\"Early stopping at epoch {i}\")\n",
        "                break\n",
        "\n",
        "        print(best_iou)\n",
        "        print(best_params_iou)\n",
        "\n",
        "# Print the best hyperparameters and validation IOU\n",
        "print('Best hyperparameters for IOU:', best_params_iou)\n",
        "print('Best validation IOU:', best_iou)\n",
        "print('Best hyperparameters for accuracy:', best_params_accuracy)\n",
        "print('Best validation accuracy:', best_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set seeds for training"
      ],
      "metadata": {
        "id": "TFxmfOPDh6IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(seed_all)\n",
        "np.random.seed(seed_all)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.cuda.manual_seed_all(seed_all)"
      ],
      "metadata": {
        "id": "u5a3fWQih7s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MRpxUGWiDTu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "max_valid_iou = 0\n",
        "start = 0\n",
        "\n",
        "epochs = []\n",
        "training_losses = []\n",
        "training_accuracies = []\n",
        "training_ious = []\n",
        "valid_losses = []\n",
        "valid_accuracies = []\n",
        "valid_ious = []\n",
        "\n",
        "\n",
        "training_precision = []\n",
        "training_recall = []\n",
        "training_f1 = []\n",
        "valid_precision = []\n",
        "valid_recall = []\n",
        "valid_f1 = []\n",
        "\n",
        "max_valid_iou_state_dict = {}\n",
        "\n",
        "for i in range(start, 100):\n",
        "  train_validation_loop(net, optimizer, scheduler, train_loader, valid_loader, test_loader, 10, i)\n",
        "  epochs.append(i)\n",
        "  x = epochs\n",
        "\n",
        "  # plt.plot(x, training_losses.cpu(), label='training losses')\n",
        "  # plt.plot(x, training_accuracies, 'tab:orange', label='training accuracy')\n",
        "  # plt.plot(x, training_ious, 'tab:purple', label='training iou')\n",
        "  # plt.plot(x, valid_losses, label='valid losses')\n",
        "  # plt.plot(x, valid_accuracies, 'tab:red',label='valid accuracy')\n",
        "  # plt.plot(x, valid_ious, 'tab:green',label='valid iou')\n",
        "  # plt.legend(loc=\"upper left\")\n",
        "\n",
        "  f1 = plt.figure()\n",
        "  ax1 = f1.add_subplot(111)\n",
        "  ax1.plot(x, [l.detach().cpu().numpy() for l in training_losses], label='training losses', color = \"#4286f4\")\n",
        "  ax1.plot(x, [a.detach().cpu().numpy() for a in training_accuracies], label='training accuracy', color = \"#0066cc\")\n",
        "  ax1.plot(x, [iou.detach().cpu().numpy() for iou in training_ious], label='training iou', color = \"#003d99\")\n",
        "  ax1.plot(x, [l.detach().cpu().numpy() for l in valid_losses], label='valid losses', color = \"#ff4d4d\")\n",
        "  ax1.plot(x, [a.detach().cpu().numpy() for a in valid_accuracies],label='valid accuracy', color = \"#cc0000\")\n",
        "  ax1.plot(x, [iou.detach().cpu().numpy() for iou in valid_ious],label='valid iou', color = \"#990000\")\n",
        "  ax1.legend(loc='upper left', bbox_to_anchor=(1.05, 1))\n",
        "\n",
        "  display(plt.show())\n",
        "\n",
        "  print(\"max valid iou:\", max_valid_iou)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}